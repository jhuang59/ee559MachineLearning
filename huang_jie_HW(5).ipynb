{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as pyplot\n",
    "import io\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy.stats import bootstrap\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the time-domain features from dataset, one dataset one instance\n",
    "#input:directory of data folder\n",
    "#return:instances from dataset\n",
    "#columns:features row:instance\n",
    "def instance(dir):\n",
    "    #create columns title\n",
    "    #example \"min2\"\n",
    "    column=list()\n",
    "    for i in range(1,7):\n",
    "            column.append(\"min\"+str(i))\n",
    "            column.append(\"max\"+str(i))\n",
    "            column.append(\"mean\"+str(i))\n",
    "            column.append(\"median\"+str(i))\n",
    "            column.append(\"standard_dev\"+str(i))\n",
    "            column.append(\"first_quar\"+str(i))\n",
    "            column.append(\"third_quar\"+str(i))\n",
    "    total=pd.DataFrame()\n",
    "    # print(os.listdir(dir))\n",
    "    #read files in folder and compute features\n",
    "    for f in os.listdir(dir):\n",
    "        if not (f.endswith('DS_Store')):\n",
    "            features=list()\n",
    "            data = pd.read_csv(os.path.join(dir,f), skiprows=4)\n",
    "            # print(\"\\n\",f)\n",
    "            summary_table=data.describe().transpose()\n",
    "            summary_table = summary_table.rename(columns={\n",
    "            '50%': 'median',\n",
    "            'min': 'min',\n",
    "            'max': 'max',\n",
    "            '25%': 'first_quar',\n",
    "            '75%': 'third_quar'})\n",
    "            # print(summary_table)\n",
    "            #reorganize features to a single row\n",
    "            for i in range(1,7):\n",
    "                for j in [\"min\",\"max\",\"mean\",\"median\",\"std\",\"first_quar\",\"third_quar\"]:\n",
    "                    features.append(summary_table[j][i])\n",
    "            # print(\"shape\",np.shape(features))\n",
    "            total=total.append([features],ignore_index=True)\n",
    "            # print(total)\n",
    "    #rename columns\n",
    "    total.columns=column\n",
    "    return total\n",
    "\n",
    "#call instance method for folders in data\n",
    "#instances is a dataframe contains 88 instances\n",
    "#input:dir_data:path of data folder\n",
    "#return:a dataFrame contains instances\n",
    "#columns:features row:instance\n",
    "def sum_instance(dir_data):\n",
    "    instances=pd.DataFrame()\n",
    "    print(os.listdir(dir_data))\n",
    "    for f in os.listdir(dir_data):\n",
    "        if not (f.endswith('DS_Store')):\n",
    "            print(os.path.join(dir_data,f))      \n",
    "            instances=pd.concat([instances,instance(os.path.join(dir_data,f))])\n",
    "    return instances\n",
    "\n",
    "#call instance_breakf method for folders in data\n",
    "#instances is a dataframe contains 88 instances\n",
    "#input:dir_data:path of data folder\n",
    "#return:a dataFrame contains instances\n",
    "#columns:features row:instance\n",
    "def sum_instancef(dir_data,piec):\n",
    "    instances=pd.DataFrame()\n",
    "    \n",
    "    for f in os.listdir(dir_data):\n",
    "        if not (f.endswith('DS_Store')):\n",
    "                 \n",
    "            instances=pd.concat([instances,instance_breakf(os.path.join(dir_data,f),piec)])\n",
    "    return instances\n",
    "\n",
    "#Break each time series in your training set into two (approximately) equal length time series.\n",
    "#Extract the time-domain features from dataset, one dataset one instance\n",
    "#input:directory of data folder\n",
    "#piec:break each series into pieces. Example: piec=2 break each series into two equal length series. more features generated\n",
    "#return:instances from dataset\n",
    "#columns:true label + features \n",
    "#row:instance\n",
    "def instance_breakf(dir,piec):\n",
    "    #create columns title\n",
    "    #example \"min2\"\n",
    "    #index for new generate features start from 7\n",
    "    #number of coulmns=piec*number of time series+1\n",
    "    column=list()\n",
    "    column.append(\"true_label\")\n",
    "    for i in range(1,piec*6+1):\n",
    "            column.append(\"min\"+str(i))\n",
    "            column.append(\"max\"+str(i))\n",
    "            column.append(\"mean\"+str(i))\n",
    "            column.append(\"median\"+str(i))\n",
    "            column.append(\"standard_dev\"+str(i))\n",
    "            column.append(\"first_quar\"+str(i))\n",
    "            column.append(\"third_quar\"+str(i))\n",
    "\n",
    "    #all instances\n",
    "    total=pd.DataFrame()\n",
    "    # print(os.listdir(dir))\n",
    "    #read files in folder and compute features\n",
    "    for f in os.listdir(dir):\n",
    "        if not (f.endswith('DS_Store')):\n",
    "            #features for each instance\n",
    "            temp=list()\n",
    "            \n",
    "            data = pd.read_csv(os.path.join(dir,f), skiprows=4)\n",
    "            #break data into pieces and extract features from each pieces\n",
    "            for p in np.array_split(data,piec):\n",
    "                # print(p)\n",
    "                features=list()\n",
    "                # print(\"\\n\",f)\n",
    "                summary_table=p.describe().transpose()\n",
    "                summary_table = summary_table.rename(columns={\n",
    "                '50%': 'median',\n",
    "                'min': 'min',\n",
    "                'max': 'max',\n",
    "                '25%': 'first_quar',\n",
    "                '75%': 'third_quar'})\n",
    "                # print(summary_table)\n",
    "                #reorganize features to a single row\n",
    "                for i in range(1,7):\n",
    "                    for j in [\"min\",\"max\",\"mean\",\"median\",\"std\",\"first_quar\",\"third_quar\"]:\n",
    "                        features.append(summary_table[j][i])\n",
    "                # print(\"shape\",np.shape(features))\n",
    "                #concatenate two lists, breaking series provide more features instead of instance\n",
    "                temp=temp+features\n",
    "                # print(temp)\n",
    "            total=total.append([[dir]+temp],ignore_index=True)\n",
    "                # print(total)\n",
    "    #rename columns\n",
    "    total.columns=column\n",
    "    return total\n",
    "\n",
    "#Break each time series in your training set into two (approximately) equal length time series.\n",
    "#Extract the time-domain features from dataset, one dataset one instance\n",
    "#input:directory of data folder\n",
    "#piec:break each series into pieces. Example: piec=2 break each series into two equal length series. more instance generated\n",
    "#return:instances from dataset\n",
    "#columns:features row:instance\n",
    "def instance_break(dir,piec):\n",
    "    #create columns title\n",
    "    #example \"min2\"\n",
    "    column=list()\n",
    "    for i in range(1,7):\n",
    "            column.append(\"min\"+str(i))\n",
    "            column.append(\"max\"+str(i))\n",
    "            column.append(\"mean\"+str(i))\n",
    "            column.append(\"median\"+str(i))\n",
    "            column.append(\"standard_dev\"+str(i))\n",
    "            column.append(\"first_quar\"+str(i))\n",
    "            column.append(\"third_quar\"+str(i))\n",
    "    #all instances\n",
    "    total=pd.DataFrame()\n",
    "    # print(os.listdir(dir))\n",
    "    #read files in folder and compute features\n",
    "    for f in os.listdir(dir):\n",
    "        if not (f.endswith('DS_Store')):\n",
    "            data = pd.read_csv(os.path.join(dir,f), skiprows=4)\n",
    "            #break data into pieces and extract features from each pieces\n",
    "            for p in np.array_split(data,piec):\n",
    "                # print(p)\n",
    "                features=list()\n",
    "                # print(\"\\n\",f)\n",
    "                summary_table=p.describe().transpose()\n",
    "                summary_table = summary_table.rename(columns={\n",
    "                '50%': 'median',\n",
    "                'min': 'min',\n",
    "                'max': 'max',\n",
    "                '25%': 'first_quar',\n",
    "                '75%': 'third_quar'})\n",
    "                # print(summary_table)\n",
    "                #reorganize features to a single row\n",
    "                for i in range(1,7):\n",
    "                    for j in [\"min\",\"max\",\"mean\",\"median\",\"std\",\"first_quar\",\"third_quar\"]:\n",
    "                        features.append(summary_table[j][i])\n",
    "                # print(\"shape\",np.shape(features))\n",
    "                # print(temp)\n",
    "                total=total.append([features],ignore_index=True)\n",
    "            \n",
    "                # print(total)\n",
    "    #rename columns\n",
    "    total.columns=column\n",
    "    return total\n",
    "\n",
    "\n",
    "#summarize min, mean, max of series 1,2,6 in bending activaties and other activities\n",
    "#input func:function used to extract features. func=instance or instance_break\n",
    "#input p: parameter of function instance_break() piec\n",
    "#output bending: a dataframe contains min, mean, max of series 1,2,6 in bending activaties\n",
    "#output other: a dataframe contains min, mean, max of series 1,2,6 in other activaties\n",
    "def fea_scaplot(func,p):\n",
    "    bending=pd.DataFrame()\n",
    "    other=pd.DataFrame()\n",
    "    #summarize min, mean, max of series 1,2,6 in bending activaties\n",
    "    for k in [\"bending1\",\"bending2\"]:\n",
    "        temp=pd.DataFrame()\n",
    "        if func==instance:\n",
    "            temp_instance=func(\"../data/AReM/\"+k)\n",
    "        elif func==instance_break:\n",
    "            temp_instance=func(\"../data/AReM/\"+k,p)\n",
    "        for i in [\"min\",\"mean\",\"max\"]:\n",
    "            for j in [\"1\",\"2\",\"6\"]:\n",
    "                #concat columns\n",
    "                temp=pd.concat([temp,temp_instance[i+j]],axis=1)   \n",
    "        #concat rows        \n",
    "        bending=pd.concat([bending,temp],axis=0,ignore_index=True) \n",
    "    #summarize min, mean, max of series 1,2,6 in other activaties\n",
    "    for k in [\"cycling\",\"lying\",\"sitting\",\"standing\",\"walking\"]:\n",
    "        temp=pd.DataFrame()\n",
    "        if func==instance:\n",
    "            temp_instance=func(\"../data/AReM/\"+k)\n",
    "        elif func==instance_break:\n",
    "            temp_instance=func(\"../data/AReM/\"+k,p)\n",
    "        for i in [\"min\",\"mean\",\"max\"]:\n",
    "            for j in [\"1\",\"2\",\"6\"]:\n",
    "                #concat columns\n",
    "                temp=pd.concat([temp,temp_instance[i+j]],axis=1)   \n",
    "        #concat rows        \n",
    "        other=pd.concat([other,temp],axis=0,ignore_index=True)\n",
    "    bending.sort_index()\n",
    "    other.sort_index()\n",
    "    return bending,other\n",
    "\n",
    "#find the value of (l,p)\n",
    "#Break each time series in your training set into l pieces\n",
    "#p is the number of features used in recursive feature elimination\n",
    "#input piec: l\n",
    "#output rfecv.n_features_: best value of p\n",
    "#output max(rfecv.cv_results_[\"mean_test_score\"]): maximum of test accuracy\n",
    "def model_selec(piec):\n",
    "    temp=sum_instancef(\"../data/AReM\",piec)\n",
    "    data_train=temp.iloc[:,1:]\n",
    "    data_label=list()\n",
    "    for i in temp.iloc[:,0]:\n",
    "        if (i==\"../data/AReM/bending1\")|(i==\"../data/AReM/bending2\"):\n",
    "            data_label.append(1)\n",
    "        else:\n",
    "            data_label.append(0)\n",
    "    # Minimum number of features to consider\n",
    "    min_features_to_select = 1\n",
    "    clf = LogisticRegression()\n",
    "    cv = StratifiedKFold(5)\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"precision\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    rfecv.fit(data_train,data_label)\n",
    "    \n",
    "    return rfecv.n_features_,max(rfecv.cv_results_[\"mean_test_score\"]),rfecv\n",
    "#find the value of (l,p)\n",
    "#Break each time series in your training set into l pieces\n",
    "#p is the number of features used in recursive feature elimination\n",
    "#input piec: l\n",
    "#output rfecv.n_features_: best value of p\n",
    "#output max(rfecv.cv_results_[\"mean_test_score\"]): maximum of test accuracy\n",
    "def model_selecL1(piec):\n",
    "    temp=sum_instancef(\"../data/AReM\",piec)\n",
    "    data_train=temp.iloc[:,1:]\n",
    "    data_label=list()\n",
    "    for i in temp.iloc[:,0]:\n",
    "        if (i==\"../data/AReM/bending1\")|(i==\"../data/AReM/bending2\"):\n",
    "            data_label.append(1)\n",
    "        else:\n",
    "            data_label.append(0)\n",
    "    # Minimum number of features to consider\n",
    "    min_features_to_select = 1\n",
    "    clf = LogisticRegression(penalty=\"l1\",solver=\"saga\")\n",
    "    cv = StratifiedKFold(5)\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    rfecv.fit(data_train,data_label)\n",
    "    return rfecv.n_features_,max(rfecv.cv_results_[\"mean_test_score\"]),rfecv\n",
    "\n",
    "#find the value of (l,p)\n",
    "#Break each time series in your training set into l pieces\n",
    "#p is the number of features used in recursive feature elimination\n",
    "#input piec: l\n",
    "#output rfecv.n_features_: best value of p\n",
    "#output max(rfecv.cv_results_[\"mean_test_score\"]): maximum of test accuracy\n",
    "#output rfecv:\n",
    "def model_selecL1_multi(piec):\n",
    "    temp=sum_instancef(\"../data/AReM\",piec)\n",
    "    data_train=temp.iloc[:,1:]\n",
    "    data_label=list()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data_label=le.fit_transform(temp.iloc[:,0])\n",
    "    min_features_to_select = 1\n",
    "    clf = LogisticRegression(penalty=\"l1\",solver=\"saga\",multi_class=\"multinomial\")\n",
    "    cv = StratifiedKFold(5)\n",
    "    rfecv = RFECV(\n",
    "        estimator=clf,\n",
    "        step=1,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        min_features_to_select=min_features_to_select,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    rfecv.fit(data_train,data_label)\n",
    "    return rfecv.n_features_,max(rfecv.cv_results_[\"mean_test_score\"]),rfecv\n",
    "\n",
    "#Create p Principal Components\n",
    "def apply_pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca\n",
    "#Cross validate on the (l, p) pair to build a Na ̈ıve Bayes’ classifier based on the PCA features\n",
    "#output best_l\n",
    "#output best_p\n",
    "def model_naive_pca():\n",
    "    best_accuracy=0\n",
    "    estimator=GaussianNB()\n",
    "    for l in range(1, 21):\n",
    "        temp=sum_instancef(\"../data/AReM\",l)\n",
    "        data_train=temp.iloc[:,1:]\n",
    "        data_label=list()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        data_label=le.fit_transform(temp.iloc[:,0])\n",
    "        \n",
    "        #build test data and label\n",
    "        temp=sum_instancef(\"../data/data_testing\",l)\n",
    "        data_test=temp.iloc[:,1:]\n",
    "        data_label_test=list()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        data_label_test=le.fit_transform(temp.iloc[:,0])\n",
    "        for p in range(1, 20):\n",
    "            data_train_pca=apply_pca(data_train,p)\n",
    "            data_test_pca=apply_pca(data_test,p)\n",
    "            estimator.fit(data_train_pca,data_label)\n",
    "            y_pred=estimator.predict(data_test_pca)\n",
    "            accuracy=accuracy_score(data_label_test, y_pred)\n",
    "            if accuracy> best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_l = l\n",
    "                best_p = p\n",
    "                y_pred_best=y_pred\n",
    "        \n",
    "    return best_l,best_p,best_accuracy,y_pred_best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)ii new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape\",np.shape(sum_instance(\"../data/AReM\")))\n",
    "data_train=sum_instance(\"../data/AReM\")\n",
    "print(\"shape\",np.shape(sum_instance(\"../data/data_testing\")))\n",
    "data_test=sum_instance(\"../data/data_testing\")\n",
    "instances=pd.concat([sum_instance(\"../data/AReM\"),sum_instance(\"../data/data_testing\")])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataset\n",
    "instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation of features\n",
    "np.std(instances,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence interval of for the standard deviation of each feature\n",
    "res=bootstrap([instances],np.std,confidence_level=0.9)\n",
    "print(\"shape of confidence interval\",np.shape(res.confidence_interval))\n",
    "res.confidence_interval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)iv\n",
    "\n",
    "choose min, mean, and max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot features \n",
    "bending=fea_scaplot(instance,2)[0]\n",
    "other=fea_scaplot(instance,2)[1]\n",
    "for i in [\"min\",\"mean\",\"max\"]:\n",
    "        pyplot.figure()\n",
    "        for j in [\"1\",\"2\",\"6\"]:\n",
    "            pyplot.scatter(x=bending.index,y=bending[i+j],color='r') \n",
    "            pyplot.scatter(x=other.index,y=other[i+j],color='b')  \n",
    "        pyplot.title(i)    \n",
    "        pyplot.legend([\"bending\",\"other\"])\n",
    "        pyplot.show()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(a)i\n",
    "\n",
    "break each time series and plot scatter plots\n",
    "\n",
    "Explanation: Compared to the result from 3(c)v, breaking time series provides high-variance samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot features \n",
    "bending=fea_scaplot(instance,2)[0]\n",
    "other=fea_scaplot(instance,2)[1]\n",
    "bending_break=fea_scaplot(instance_break,2)[0]\n",
    "other_break=fea_scaplot(instance_break,2)[1]\n",
    "for i in [\"min\",\"mean\",\"max\"]:\n",
    "        pyplot.subplot(1,2,1)\n",
    "        for j in [\"1\",\"2\",\"6\"]:\n",
    "            pyplot.scatter(x=bending.index,y=bending[i+j],color='r') \n",
    "            pyplot.scatter(x=other.index,y=other[i+j],color='b')  \n",
    "        pyplot.title(i+\"nonbreak\")\n",
    "        pyplot.subplot(1,2,2)\n",
    "        for j in [\"1\",\"2\",\"6\"]:\n",
    "            pyplot.scatter(x=bending_break.index,y=bending_break[i+j],color='r') \n",
    "            pyplot.scatter(x=other_break.index,y=other_break[i+j],color='b')  \n",
    "        pyplot.title(i+\"break\")    \n",
    "        pyplot.legend([\"bending\",\"other\"])\n",
    "        pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(a)ii\n",
    "\n",
    "The right way to perform cross-validation:\n",
    "\n",
    "1.break trainning set into l time series\n",
    "\n",
    "2.divide trainning set into k folds\n",
    "\n",
    "3.fit model with k-1 folds data\n",
    "\n",
    "4.compute p-value of parameters\n",
    "\n",
    "5.eliminate features\n",
    "\n",
    "6.test model with k fold\n",
    "\n",
    "7.go back to step 3\n",
    "\n",
    "8 average the test error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best value of l and p\n",
    "accuracy=list()\n",
    "p=list()\n",
    "for i in range(1,21):\n",
    "    temp=model_selec(i)\n",
    "    accuracy.append(temp[1])\n",
    "    p.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the precision and p value\n",
    "pyplot.subplot(2,1,1)\n",
    "pyplot.plot(accuracy)\n",
    "pyplot.title(\"accuracy\")\n",
    "pyplot.subplot(2,1,2)\n",
    "pyplot.title(\"p_value\")\n",
    "pyplot.plot(p)\n",
    "print(\"precision of train data\",max(accuracy))\n",
    "print(p)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best value of l is 18, and corresponding p is 1\n",
    "(18,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(a)iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build train data and label\n",
    "temp=sum_instancef(\"../data/AReM\",18)\n",
    "data_train=temp.iloc[:,1:]\n",
    "data_label=list()\n",
    "for i in temp.iloc[:,0]:\n",
    "    if (i==\"../data/AReM/bending1\")|(i==\"../data/AReM/bending2\"):\n",
    "        data_label.append(1)\n",
    "    else:\n",
    "        data_label.append(0)\n",
    "#model with best value of l and p\n",
    "model=model_selec(18)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on trainning data\n",
    "y_pred=model.predict(data_train)\n",
    "accuracy=1-sum(abs(y_pred-data_label))/len(y_pred)\n",
    "\n",
    "model.support_\n",
    "#selected feature\n",
    "select=data_train.columns[model.support_]\n",
    "#use selected feature to fit logit model and compute the p-value of coefficient\n",
    "X_train_with_constant = sm.add_constant(data_train[select])\n",
    "logit_model = sm.Logit(data_label, X_train_with_constant)\n",
    "logit_results = logit_model.fit()\n",
    "p_values = logit_results.pvalues\n",
    "#comfusion mattrix\n",
    "cm = confusion_matrix(data_label, y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "# Get the predicted probabilities for positive class from the classifier\n",
    "y_train_pred_proba = model.predict_proba(data_train)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(data_label, y_train_pred_proba)\n",
    "# Calculate the AUC (Area Under the Curve)\n",
    "auc_score = auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy train\",accuracy)\n",
    "print(\"selected features:\\n\",select)\n",
    "print(\"p value:\\n\",p_values)\n",
    "print(\"parameter:\\n\",model.estimator_.coef_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "pyplot.plot(fpr, tpr)\n",
    "pyplot.title(\"ROC curve\")\n",
    "# Print the AUC score\n",
    "print(\"AUC:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(a)iv \n",
    "\n",
    "Test the classifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build test data and label\n",
    "temp=sum_instancef(\"../data/data_testing\",18)\n",
    "data_test=temp.iloc[:,1:]\n",
    "data_label_test=list()\n",
    "for i in temp.iloc[:,0]:\n",
    "    if (i==\"../data/data_testing/bending1\")|(i==\"../data/data_testing/bending2\"):\n",
    "        data_label_test.append(1)\n",
    "    else:\n",
    "        data_label_test.append(0)\n",
    "#prediction on test data\n",
    "y_pred_test=model.predict(data_test)\n",
    "accuracy_test=1-sum(abs(y_pred_test-data_label_test))/len(y_pred_test)\n",
    "print(\"accuracy test\",accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare to accuracy of train data(1), precision of test data is lower(0.9473684210526316)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(a)v\n",
    "\n",
    "yes, most of positive class are at the begin of data. The rest of data are negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(a)vi\n",
    "\n",
    "yes, there are 60 positive samples and 9 negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_major = [i for i, value in enumerate(data_label) if value == 0]\n",
    "ind_min = [i for i, value in enumerate(data_label) if value == 1]\n",
    "\n",
    "majority_class = data_train.iloc[ind_major] \n",
    "minority_class = data_train.iloc[ind_min]\n",
    "# Upsample the minority class to match the number of majority class samples\n",
    "minority_upsampled = resample(minority_class, n_samples=len(majority_class), replace=True, random_state=42)\n",
    "data_train_balanced = np.vstack((majority_class, minority_upsampled))\n",
    "data_label_balanced = np.concatenate((np.zeros(len(majority_class)), np.ones(len(minority_upsampled))))\n",
    "print(np.shape(data_train_balanced))\n",
    "model.fit(data_train_balanced,data_label_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(data_train_balanced)\n",
    "accuracy=1-sum(abs(y_pred-data_label_balanced))/len(data_label_balanced)\n",
    "print(\"accuracy train\",accuracy)\n",
    "#comfusion mattrix\n",
    "cm = confusion_matrix(data_label_balanced, y_pred)\n",
    "# Get the predicted probabilities for positive class from the classifier\n",
    "y_train_pred_proba = model.predict_proba(data_train_balanced)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(data_label_balanced, y_train_pred_proba)\n",
    "# Calculate the AUC (Area Under the Curve)\n",
    "auc_score = auc(fpr, tpr)\n",
    "print(\"confusion mattrix\\n\",cm)\n",
    "pyplot.figure(1)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "pyplot.figure(2)\n",
    "pyplot.title(\"ROC curve\")\n",
    "pyplot.plot(fpr, tpr)\n",
    "# Print the AUC score\n",
    "print(\"AUC:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best value of l and p\n",
    "accuracy=list()\n",
    "p=list()\n",
    "for i in range(1,10):\n",
    "    temp=model_selecL1(i)\n",
    "    accuracy.append(temp[1])\n",
    "    p.append(temp[0])\n",
    "for i in range(10,21):\n",
    "    temp=model_selecL1(i)\n",
    "    accuracy.append(temp[1])\n",
    "    p.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the precision and p value\n",
    "pyplot.subplot(2,1,1)\n",
    "pyplot.plot(accuracy)\n",
    "pyplot.title(\"accuracy\")\n",
    "pyplot.subplot(2,1,2)\n",
    "pyplot.title(\"number of features\")\n",
    "pyplot.plot(p)\n",
    "print(\"precision of train data\",max(accuracy))\n",
    "print(p)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with variable selection using p-values, l1-penalized performs better. The accuracy of l1-penalized(0.9714) is higher than that of variable selection using p-values(0.93) l1-penalty is easier to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(c)i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best value of l and p\n",
    "accuracy=list()\n",
    "p=list()\n",
    "for i in range(1,10):\n",
    "    temp=model_selecL1_multi(i)\n",
    "    accuracy.append(temp[1])\n",
    "    p.append(temp[0])\n",
    "for i in range(10,21):\n",
    "    temp=model_selecL1_multi(i)\n",
    "    accuracy.append(temp[1])\n",
    "    p.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the precision and p value\n",
    "pyplot.subplot(2,1,1)\n",
    "pyplot.plot(accuracy)\n",
    "pyplot.title(\"accuracy\")\n",
    "pyplot.subplot(2,1,2)\n",
    "pyplot.title(\"number of features\")\n",
    "pyplot.plot(p)\n",
    "pyplot.xlabel(\"L\")\n",
    "print(\"precision of train data\",max(accuracy))\n",
    "print(p)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose l=1 p=29\n",
    "test model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_selecL1_multi(1)[2]\n",
    "model.n_features_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build test data and label\n",
    "temp=sum_instancef(\"../data/data_testing\",1)\n",
    "data_test=temp.iloc[:,1:]\n",
    "data_label_test=list()\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_label_test=le.fit_transform(temp.iloc[:,0])\n",
    "#prediction on test data\n",
    "y_pred_test=model.predict(data_test)\n",
    "accuracy_test=1-sum(abs(y_pred_test-data_label_test))/len(y_pred_test)\n",
    "print(\"accuracy test\",accuracy_test)\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comfusion mattrix\n",
    "cm = confusion_matrix(data_label_test, y_pred_test)\n",
    "# Get the predicted probabilities for positive class from the classifier\n",
    "y_train_pred_proba = model.predict_proba(data_test)[:, 1]\n",
    "# Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(data_label_test, y_train_pred_proba)\n",
    "# Calculate the AUC (Area Under the Curve)\n",
    "# auc_score = auc(fpr, tpr)\n",
    "print(\"confusion mattrix\\n\",cm)\n",
    "# pyplot.plot(fpr, tpr)\n",
    "# pyplot.title(\"ROC curve\")\n",
    "pyplot.figure(1)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(c)ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test Gaussian pdf naive bayes classifier\n",
    "temp=sum_instancef(\"../data/AReM\",1)\n",
    "data_train=temp.iloc[:,1:]\n",
    "data_label=list()\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_label=le.fit_transform(temp.iloc[:,0])\n",
    "model.transform(data_train)\n",
    "estimator=GaussianNB()\n",
    "estimatormul=MultinomialNB()\n",
    "estimator.fit(model.transform(data_train),data_label)\n",
    "estimatormul.fit(model.transform(data_train),data_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "y_pred_test=estimator.predict(model.transform(data_test))\n",
    "accuracy_test=1-sum(abs(y_pred_test-data_label_test))/len(y_pred_test)\n",
    "print(\"accuracy test\",accuracy_test)\n",
    "print(y_pred_test)\n",
    "#comfusion mattrix\n",
    "cm = confusion_matrix(data_label_test, y_pred_test)\n",
    "\n",
    "print(\"confusion mattrix\\n\",cm)\n",
    "#prediction on test data\n",
    "y_pred_test=estimatormul.predict(model.transform(data_test))\n",
    "accuracy_test=1-sum(abs(y_pred_test-data_label_test))/len(y_pred_test)\n",
    "print(\"accuracy test\",accuracy_test)\n",
    "print(y_pred_test)\n",
    "#comfusion mattrix\n",
    "cm1 = confusion_matrix(data_label_test, y_pred_test)\n",
    "\n",
    "print(\"confusion mattrix\\n\",cm1)\n",
    "\n",
    "pyplot.subplot(1,2,1)\n",
    "pyplot.title(\"Gaussian confusion\")\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "pyplot.subplot(1,2,2)\n",
    "pyplot.title(\"Multinomial confusion\")\n",
    "sns.heatmap(cm1, annot=True, cmap='Blues')\n",
    "pyplot.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(c)iii\n",
    "\n",
    "Report test error and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l,best_p,best_accuracy,y_pred_best=model_naive_pca()\n",
    "print(\"best_l,best_p,best_accuracy,y_pred_best\\n\",best_l,best_p,best_accuracy,y_pred_best)\n",
    "error=1-best_accuracy\n",
    "print(\"test error\",error)\n",
    "cm=confusion_matrix(data_label_test,y_pred_best)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the scatterplot of the classes in your training data based on the first and second principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train_pca=apply_pca(data_train,2)\n",
    "data_train_pca_12=data_train_pca[:,0:2]\n",
    "# print(np.shape(np.array(data_train_pca_12)))\n",
    "# print(np.shape(np.array(data_train_pca_12)[:,1]))\n",
    "# print(np.shape(np.array(data_train_pca_12)[:,0]))\n",
    "sns.scatterplot(x=data_train_pca_12[:,0],y=data_train_pca_12[:,1], hue=data_label, data=data_train_pca_12)\n",
    "pyplot.xlabel(\"First Principal Component\")\n",
    "pyplot.ylabel(\"Second Principal Component\")\n",
    "pyplot.title(\"Scatterplot of Classes based on PCA\")\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Binary and Multiclass Classification\n",
    "(c)iv\n",
    "\n",
    "From my observation, logistic regression with l1 penalty perform well in multilabel classification. While naive bayes classifier perform well in binomial problem. Thuis is because dataset is imbalance in binomial problem and naive bayes is robust to imbalance dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee541_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
